{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Image Classification via WideResNet + SAM on FashionMNIST dataset\n",
    "based on (Adaptive) SAM Optimizer https://github.com/davda54/sam repo."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Initialization\n",
    "To ensure results are reproducible"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda:0 device\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "\n",
    "def init_random(seed):\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    torch.backends.cudnn.enabled = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.backends.cudnn.deterministic = False\n",
    "\n",
    "init_random(42)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"using {device} device\")\n",
    "\n",
    "# hyper parameters\n",
    "hparams = {}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataset with augmentation and preprocessing\n",
    "For augmentation I use a small jitter in position via RandomCrop; random flip around vertical axis and random erasing / cutout.\n",
    "I did experiments with AugMix and AutoAugment learnt on CIFAR10, but results were not better."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "class FashionMNIST:\n",
    "    def __init__(self, batch_size, threads):\n",
    "        self.image_size = (28, 28)\n",
    "\n",
    "        # gather statistics\n",
    "        def get_statistics(train_set):\n",
    "            data = torch.cat([d[0] for d in DataLoader(train_set)])\n",
    "            return data.mean(dim=[0, 2, 3]), data.std(dim=[0, 2, 3])\n",
    "\n",
    "        mean, std = get_statistics(\n",
    "            datasets.FashionMNIST(root='./fashionmnist', train=True, download=True, transform=transforms.ToTensor()))\n",
    "\n",
    "        train_transform = transforms.Compose([\n",
    "            transforms.RandomCrop(size=self.image_size, padding=4),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean, std),\n",
    "            transforms.RandomErasing(),\n",
    "        ])\n",
    "\n",
    "        test_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean, std)\n",
    "        ])\n",
    "\n",
    "        self.infer_transform = transforms.Compose([\n",
    "            transforms.Grayscale(),\n",
    "            transforms.Resize(self.image_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean, std)\n",
    "        ])\n",
    "\n",
    "        self.train_set = datasets.FashionMNIST(root='./data', train=True, download=True, transform=train_transform)\n",
    "        self.test_set = datasets.FashionMNIST(root='./data', train=False, download=True, transform=test_transform)\n",
    "\n",
    "        self.train = DataLoader(self.train_set, batch_size=batch_size, shuffle=True, num_workers=threads)\n",
    "        self.test = DataLoader(self.test_set, batch_size=batch_size, shuffle=False, num_workers=threads)\n",
    "\n",
    "        self.classes = self.train_set.classes\n",
    "\n",
    "\n",
    "dataset = FashionMNIST(batch_size=128, threads=2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define Wide ResNet model\n",
    "I use WRN-16-8 architecture with dropouts. Experiment with WRN-28-10 did not show an improvement."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WideResNet(\n",
      "  (f): Sequential(\n",
      "    (0_convolution): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1_block): Block(\n",
      "      (block): Sequential(\n",
      "        (0): DownsampleUnit(\n",
      "          (norm_act): Sequential(\n",
      "            (0_normalization): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (1_activation): ReLU()\n",
      "          )\n",
      "          (block): Sequential(\n",
      "            (0_convolution): Conv2d(16, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (1_normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2_activation): ReLU()\n",
      "            (3_dropout): Dropout(p=0.3, inplace=False)\n",
      "            (4_convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (downsample): Conv2d(16, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (1): BasicUnit(\n",
      "          (block): Sequential(\n",
      "            (0_normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (1_activation): ReLU()\n",
      "            (2_convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (3_normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (4_activation): ReLU()\n",
      "            (5_dropout): Dropout(p=0.3, inplace=False)\n",
      "            (6_convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "        )\n",
      "        (2): BasicUnit(\n",
      "          (block): Sequential(\n",
      "            (0_normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (1_activation): ReLU()\n",
      "            (2_convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (3_normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (4_activation): ReLU()\n",
      "            (5_dropout): Dropout(p=0.3, inplace=False)\n",
      "            (6_convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2_block): Block(\n",
      "      (block): Sequential(\n",
      "        (0): DownsampleUnit(\n",
      "          (norm_act): Sequential(\n",
      "            (0_normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (1_activation): ReLU()\n",
      "          )\n",
      "          (block): Sequential(\n",
      "            (0_convolution): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (1_normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2_activation): ReLU()\n",
      "            (3_dropout): Dropout(p=0.3, inplace=False)\n",
      "            (4_convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (downsample): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        )\n",
      "        (1): BasicUnit(\n",
      "          (block): Sequential(\n",
      "            (0_normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (1_activation): ReLU()\n",
      "            (2_convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (3_normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (4_activation): ReLU()\n",
      "            (5_dropout): Dropout(p=0.3, inplace=False)\n",
      "            (6_convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "        )\n",
      "        (2): BasicUnit(\n",
      "          (block): Sequential(\n",
      "            (0_normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (1_activation): ReLU()\n",
      "            (2_convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (3_normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (4_activation): ReLU()\n",
      "            (5_dropout): Dropout(p=0.3, inplace=False)\n",
      "            (6_convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3_block): Block(\n",
      "      (block): Sequential(\n",
      "        (0): DownsampleUnit(\n",
      "          (norm_act): Sequential(\n",
      "            (0_normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (1_activation): ReLU()\n",
      "          )\n",
      "          (block): Sequential(\n",
      "            (0_convolution): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (1_normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2_activation): ReLU()\n",
      "            (3_dropout): Dropout(p=0.3, inplace=False)\n",
      "            (4_convolution): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (downsample): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        )\n",
      "        (1): BasicUnit(\n",
      "          (block): Sequential(\n",
      "            (0_normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (1_activation): ReLU()\n",
      "            (2_convolution): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (3_normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (4_activation): ReLU()\n",
      "            (5_dropout): Dropout(p=0.3, inplace=False)\n",
      "            (6_convolution): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "        )\n",
      "        (2): BasicUnit(\n",
      "          (block): Sequential(\n",
      "            (0_normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (1_activation): ReLU()\n",
      "            (2_convolution): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (3_normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (4_activation): ReLU()\n",
      "            (5_dropout): Dropout(p=0.3, inplace=False)\n",
      "            (6_convolution): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4_normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5_activation): ReLU()\n",
      "    (6_pooling): AvgPool2d(kernel_size=7, stride=7, padding=0)\n",
      "    (7_flattening): Flatten(start_dim=1, end_dim=-1)\n",
      "    (8_classification): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "{'model/dropout': 0.3, 'model/depth': 16, 'model/width_factor': 8}\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "hparams |= {\n",
    "        \"model/dropout\": 0.3,\n",
    "        \"model/depth\": 16,\n",
    "        \"model/width_factor\": 8\n",
    "    }\n",
    "\n",
    "class BasicUnit(nn.Module):\n",
    "    def __init__(self, channels: int, dropout: float):\n",
    "        super(BasicUnit, self).__init__()\n",
    "        self.block = nn.Sequential(OrderedDict([\n",
    "            (\"0_normalization\", nn.BatchNorm2d(channels)),\n",
    "            (\"1_activation\", nn.ReLU()),\n",
    "            (\"2_convolution\", nn.Conv2d(channels, channels, (3, 3), stride=1, padding=1, bias=False)),\n",
    "            (\"3_normalization\", nn.BatchNorm2d(channels)),\n",
    "            (\"4_activation\", nn.ReLU()),\n",
    "            (\"5_dropout\", nn.Dropout(dropout)),\n",
    "            (\"6_convolution\", nn.Conv2d(channels, channels, (3, 3), stride=1, padding=1, bias=False)),\n",
    "        ]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.block(x)\n",
    "\n",
    "\n",
    "class DownsampleUnit(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, stride: int, dropout: float):\n",
    "        super(DownsampleUnit, self).__init__()\n",
    "        self.norm_act = nn.Sequential(OrderedDict([\n",
    "            (\"0_normalization\", nn.BatchNorm2d(in_channels)),\n",
    "            (\"1_activation\", nn.ReLU()),\n",
    "        ]))\n",
    "        self.block = nn.Sequential(OrderedDict([\n",
    "            (\"0_convolution\", nn.Conv2d(in_channels, out_channels, (3, 3), stride=stride, padding=1, bias=False)),\n",
    "            (\"1_normalization\", nn.BatchNorm2d(out_channels)),\n",
    "            (\"2_activation\", nn.ReLU()),\n",
    "            (\"3_dropout\", nn.Dropout(dropout)),\n",
    "            (\"4_convolution\", nn.Conv2d(out_channels, out_channels, (3, 3), stride=1, padding=1, bias=False)),\n",
    "        ]))\n",
    "        self.downsample = nn.Conv2d(in_channels, out_channels, (1, 1), stride=stride, padding=0, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.norm_act(x)\n",
    "        return self.block(x) + self.downsample(x)\n",
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, stride: int, depth: int, dropout: float):\n",
    "        super(Block, self).__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            DownsampleUnit(in_channels, out_channels, stride, dropout),\n",
    "            *(BasicUnit(out_channels, dropout) for _ in range(depth))\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "\n",
    "class WideResNet(nn.Module):\n",
    "    def __init__(self, depth: int, width_factor: int, dropout: float, in_channels: int, labels: int, input_size: int):\n",
    "        super(WideResNet, self).__init__()\n",
    "\n",
    "        self.filters = [16, 1 * 16 * width_factor, 2 * 16 * width_factor, 4 * 16 * width_factor, 7]\n",
    "        self.block_depth = (depth - 4) // (3 * 2)\n",
    "\n",
    "        self.f = nn.Sequential(OrderedDict([\n",
    "            # 128 x 1 x 28 x 28\n",
    "            (\"0_convolution\", nn.Conv2d(in_channels, self.filters[0], (3, 3), stride=1, padding=1, bias=False)),\n",
    "            # 128 x 16 x 28 x 28\n",
    "            (\"1_block\", Block(self.filters[0], self.filters[1], 1, self.block_depth, dropout)),\n",
    "            # 128 x 128 x 28 x 28\n",
    "            (\"2_block\", Block(self.filters[1], self.filters[2], 2, self.block_depth, dropout)),\n",
    "            # 128 x 256 x 14 x 14\n",
    "            (\"3_block\", Block(self.filters[2], self.filters[3], 2, self.block_depth, dropout)),\n",
    "            # 128 x 128 x 7 x 7\n",
    "            (\"4_normalization\", nn.BatchNorm2d(self.filters[3])),\n",
    "            # 128 x 128 x 7 x 7\n",
    "            (\"5_activation\", nn.ReLU()),\n",
    "            # 128 x 128 x 7 x 7\n",
    "            (\"6_pooling\", nn.AvgPool2d(kernel_size=input_size // 4)),\n",
    "            # 128 x 128 x 1 x 1\n",
    "            (\"7_flattening\", nn.Flatten()),\n",
    "            # 128 x 128\n",
    "            (\"8_classification\", nn.Linear(in_features=self.filters[3], out_features=labels)),\n",
    "            # 128 x 10\n",
    "        ]))\n",
    "\n",
    "        self._initialize()\n",
    "\n",
    "    def _initialize(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight.data, mode=\"fan_in\", nonlinearity=\"relu\")\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                m.weight.data.zero_()\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.f(x)\n",
    "\n",
    "\n",
    "\n",
    "model = WideResNet(depth=hparams[\"model/depth\"], width_factor=hparams[\"model/width_factor\"], dropout=hparams[\"model/dropout\"],\n",
    "                   in_channels=1, labels=10, input_size=dataset.image_size[0]).to(device)\n",
    "print(model)\n",
    "print(hparams)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Optimizer: SAM + SGD with nesterov momentum\n",
    "SAM is Sharpness-Aware Minimization that\n",
    "seeks parameters that lie in neighborhoods having uniformly low loss. It improves model generalization and provides robustness to label noise.\n",
    "See [SAM](https://arxiv.org/abs/2010.01412) and [Adaptive SAM](https://arxiv.org/abs/2102.11600) papers.\n",
    "I tested different values of rho for 30 epochs with no data augmentation and rho=1 seems to be the best."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAM (\n",
      "Parameter Group 0\n",
      "    adaptive: True\n",
      "    dampening: 0\n",
      "    differentiable: False\n",
      "    foreach: None\n",
      "    lr: 0.1\n",
      "    maximize: False\n",
      "    momentum: 0.9\n",
      "    nesterov: True\n",
      "    rho: 1\n",
      "    weight_decay: 0.0005\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "hparams |= {\"SAM/rho\": 1,\n",
    "            \"SAM/adaptive\": True}\n",
    "hparams |= {\"SGD/lr\": 0.1,\n",
    "            \"SGD/momentum\": 0.9,\n",
    "            \"SGD/weight_decay\":0.0005,\n",
    "            \"SGD/nesterov\": True\n",
    "           }\n",
    "\n",
    "class SAM(torch.optim.Optimizer):\n",
    "    def __init__(self, params, base_optimizer, rho=0.05, adaptive=False, **kwargs):\n",
    "        assert rho >= 0.0, f\"Invalid rho, should be non-negative: {rho}\"\n",
    "\n",
    "        defaults = dict(rho=rho, adaptive=adaptive, **kwargs)\n",
    "        super(SAM, self).__init__(params, defaults)\n",
    "\n",
    "        self.base_optimizer = base_optimizer(self.param_groups, **kwargs)\n",
    "        self.param_groups = self.base_optimizer.param_groups\n",
    "        self.defaults.update(self.base_optimizer.defaults)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def first_step(self, zero_grad=False):\n",
    "        grad_norm = self._grad_norm()\n",
    "        for group in self.param_groups:\n",
    "            scale = group[\"rho\"] / (grad_norm + 1e-12)\n",
    "\n",
    "            for p in group[\"params\"]:\n",
    "                if p.grad is None: continue\n",
    "                self.state[p][\"old_p\"] = p.data.clone()\n",
    "                e_w = (torch.pow(p, 2) if group[\"adaptive\"] else 1.0) * p.grad * scale.to(p)\n",
    "                p.add_(e_w)  # climb to the local maximum \"w + e(w)\"\n",
    "\n",
    "        if zero_grad: self.zero_grad()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def second_step(self, zero_grad=False):\n",
    "        for group in self.param_groups:\n",
    "            for p in group[\"params\"]:\n",
    "                if p.grad is None: continue\n",
    "                p.data = self.state[p][\"old_p\"]  # get back to \"w\" from \"w + e(w)\"\n",
    "\n",
    "        self.base_optimizer.step()  # do the actual \"sharpness-aware\" update\n",
    "\n",
    "        if zero_grad: self.zero_grad()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def step(self, closure=None):\n",
    "        assert closure is not None, \"Sharpness Aware Minimization requires closure, but it was not provided\"\n",
    "        closure = torch.enable_grad()(closure)  # the closure should do a full forward-backward pass\n",
    "\n",
    "        self.first_step(zero_grad=True)\n",
    "        closure()\n",
    "        self.second_step()\n",
    "\n",
    "    def _grad_norm(self):\n",
    "\n",
    "        # put everything on the same device, in case of model parallelism\n",
    "        shared_device = self.param_groups[0][\"params\"][0].device\n",
    "\n",
    "        norm = torch.norm(\n",
    "            torch.stack([\n",
    "                ((torch.abs(p) if group[\"adaptive\"] else 1.0) * p.grad).norm(p=2).to(shared_device)\n",
    "                for group in self.param_groups for p in group[\"params\"]\n",
    "                if p.grad is not None\n",
    "            ]),\n",
    "            p=2\n",
    "        )\n",
    "        return norm\n",
    "\n",
    "    def load_state_dict(self, state_dict):\n",
    "        super().load_state_dict(state_dict)\n",
    "        self.base_optimizer.param_groups = self.param_groups\n",
    "\n",
    "optimizer = SAM(model.parameters(), torch.optim.SGD,\n",
    "                rho=hparams[\"SAM/rho\"], adaptive=hparams[\"SAM/adaptive\"],\n",
    "                lr=hparams[\"SGD/lr\"], momentum=hparams[\"SGD/momentum\"], weight_decay=hparams[\"SGD/weight_decay\"], nesterov=hparams[\"SGD/nesterov\"])\n",
    "print(optimizer)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Functions to set BN momentum to zero to bypass the running statistics during the second pass backpropagation. (Two passes are due to SAM)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from torch.nn.modules.batchnorm import _BatchNorm\n",
    "\n",
    "class disable_running_stats:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def __enter__(self):\n",
    "        def _disable(module):\n",
    "            if isinstance(module, _BatchNorm):\n",
    "                module.backup_momentum = module.momentum\n",
    "                module.momentum = 0\n",
    "\n",
    "        self.model.apply(_disable)\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        def _enable(module):\n",
    "            if isinstance(module, _BatchNorm) and hasattr(module, \"backup_momentum\"):\n",
    "                module.momentum = module.backup_momentum\n",
    "\n",
    "        self.model.apply(_enable)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train duration\n",
    "Original paper used 200 epochs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "hparams[\"total_epochs\"] = 10"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Scheduler\n",
    "Decrease learning rate 5 times at 0.3, 0.6 and 0.8 relative epochs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "class StepLR:\n",
    "    def __init__(self, optimizer, learning_rate: float, total_epochs: int):\n",
    "        self.optimizer = optimizer\n",
    "        self.total_epochs = total_epochs\n",
    "        self.base = learning_rate\n",
    "\n",
    "    def __call__(self, epoch):\n",
    "        if epoch < self.total_epochs * 3 / 10:\n",
    "            lr = self.base\n",
    "        elif epoch < self.total_epochs * 6 / 10:\n",
    "            lr = self.base * 0.2\n",
    "        elif epoch < self.total_epochs * 8 / 10:\n",
    "            lr = self.base * 0.2 ** 2\n",
    "        else:\n",
    "            lr = self.base * 0.2 ** 3\n",
    "\n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            param_group[\"lr\"] = lr\n",
    "\n",
    "    def lr(self) -> float:\n",
    "        return self.optimizer.param_groups[0][\"lr\"]\n",
    "\n",
    "scheduler = StepLR(optimizer, learning_rate=hparams[\"SGD/lr\"], total_epochs=hparams[\"total_epochs\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loss\n",
    "Smooth labels and compute probabilities difference"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "hparams |= {\"loss/label_smoothing\": 0.1}\n",
    "\n",
    "def smooth_crossentropy(pred, gold, smoothing=hparams[\"loss/label_smoothing\"]):\n",
    "    n_class = pred.size(1)\n",
    "\n",
    "    one_hot = torch.full_like(pred, fill_value=smoothing / (n_class - 1))\n",
    "    one_hot.scatter_(dim=1, index=gold.unsqueeze(1), value=1.0 - smoothing)\n",
    "    log_prob = F.log_softmax(pred, dim=1)\n",
    "\n",
    "    return F.kl_div(input=log_prob, target=one_hot, reduction='none').sum(-1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Convenient Logging class"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "class LoadingBar:\n",
    "    def __init__(self, length: int = 40):\n",
    "        self.length = length\n",
    "        self.symbols = ['┈', '░', '▒', '▓']\n",
    "\n",
    "    def __call__(self, progress: float) -> str:\n",
    "        p = int(progress * self.length * 4 + 0.5)\n",
    "        d, r = p // 4, p % 4\n",
    "        return '┠┈' + d * '█' + (\n",
    "            (self.symbols[r]) + max(0, self.length - 1 - d) * '┈' if p < self.length * 4 else '') + \"┈┨\"\n",
    "\n",
    "\n",
    "class Log:\n",
    "    def __init__(self, log_each: int, initial_epoch=-1, writer=None):\n",
    "        self.loading_bar = LoadingBar(length=27)\n",
    "        self.best_accuracy = 0.0\n",
    "        self.log_each = log_each\n",
    "        self.epoch = initial_epoch\n",
    "        self.is_train = False\n",
    "        self.is_eval = False\n",
    "        self.initial_epoch = initial_epoch\n",
    "        self.writer = writer\n",
    "        self.epoch_state = {}\n",
    "\n",
    "    def __enter__(self):\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        self.flush()\n",
    "        self._print_footer()\n",
    "\n",
    "    def train(self, len_dataset: int) -> None:\n",
    "        self.epoch += 1\n",
    "        if self.epoch == self.initial_epoch + 1:\n",
    "            self._print_header()\n",
    "        else:\n",
    "            self.flush()\n",
    "\n",
    "        self.is_train = True\n",
    "        self.is_eval = False\n",
    "        self.last_steps_state = {\"loss\": 0.0, \"accuracy\": 0.0, \"steps\": 0}\n",
    "        self._reset(len_dataset)\n",
    "\n",
    "    def eval(self, len_dataset: int) -> None:\n",
    "        self.flush()\n",
    "        self.is_train = False\n",
    "        self.is_eval = True\n",
    "        self._reset(len_dataset)\n",
    "\n",
    "    def __call__(self, model, loss, accuracy, learning_rate: float = None) -> None:\n",
    "        if self.is_train:\n",
    "            self._train_step(model, loss, accuracy, learning_rate)\n",
    "        else:\n",
    "            self._eval_step(loss, accuracy)\n",
    "\n",
    "    def flush(self) -> None:\n",
    "        if self.is_train:\n",
    "            self.train_loss = self.epoch_state[\"loss\"] / self.epoch_state[\"steps\"]\n",
    "            self.train_accuracy = self.epoch_state[\"accuracy\"] / self.epoch_state[\"steps\"]\n",
    "            if self.writer:\n",
    "                self.writer.add_scalar(\"Loss/train\", self.train_loss, self.epoch)\n",
    "                self.writer.add_scalar(\"Accuracy/train\", self.train_accuracy, self.epoch)\n",
    "                self.writer.flush()\n",
    "\n",
    "            print(\n",
    "                f\"\\r┃{self.epoch:12d}  ┃{self.train_loss:12.4f}  │{100 * self.train_accuracy:10.2f} %  ┃{self.learning_rate:12.3e}  │{self._time():>12}  ┃\",\n",
    "                end=\"\",\n",
    "                flush=True,\n",
    "            )\n",
    "\n",
    "        elif self.is_eval:\n",
    "            loss = self.epoch_state[\"loss\"] / self.epoch_state[\"steps\"]\n",
    "            accuracy = self.epoch_state[\"accuracy\"] / self.epoch_state[\"steps\"]\n",
    "            if self.writer:\n",
    "                self.writer.add_scalar(\"Loss/eval\", loss, self.epoch)\n",
    "                self.writer.add_scalar(\"Accuracy/eval\", accuracy, self.epoch)\n",
    "                self.writer.flush()\n",
    "\n",
    "            print(f\"\\r┃{self.epoch:12d}  ┃{self.train_loss:12.4f}  │{100 * self.train_accuracy:10.2f} %  ┃{self.learning_rate:12.3e}  │{self._time():>12}  ┃{loss:12.4f}  │{100 * accuracy:10.2f} %  ┃\", flush=True)\n",
    "\n",
    "            if accuracy > self.best_accuracy:\n",
    "                self.best_accuracy = accuracy\n",
    "\n",
    "    def loss(self):\n",
    "        return self.epoch_state[\"loss\"] / self.epoch_state[\"steps\"]\n",
    "\n",
    "    def accuracy(self):\n",
    "        return self.epoch_state[\"accuracy\"] / self.epoch_state[\"steps\"]\n",
    "\n",
    "    def _train_step(self, model, loss, accuracy, learning_rate: float) -> None:\n",
    "        self.learning_rate = learning_rate\n",
    "        self.last_steps_state[\"loss\"] += loss.sum().item()\n",
    "        self.last_steps_state[\"accuracy\"] += accuracy.sum().item()\n",
    "        self.last_steps_state[\"steps\"] += loss.size(0)\n",
    "        self.epoch_state[\"loss\"] += loss.sum().item()\n",
    "        self.epoch_state[\"accuracy\"] += accuracy.sum().item()\n",
    "        self.epoch_state[\"steps\"] += loss.size(0)\n",
    "        self.step += 1\n",
    "\n",
    "        if self.step % self.log_each == self.log_each - 1:\n",
    "            loss = self.last_steps_state[\"loss\"] / self.last_steps_state[\"steps\"]\n",
    "            accuracy = self.last_steps_state[\"accuracy\"] / self.last_steps_state[\"steps\"]\n",
    "\n",
    "            self.last_steps_state = {\"loss\": 0.0, \"accuracy\": 0.0, \"steps\": 0}\n",
    "            progress = self.step / self.len_dataset\n",
    "\n",
    "            print(\n",
    "                f\"\\r┃{self.epoch:12d}  ┃{loss:12.4f}  │{100 * accuracy:10.2f} %  ┃{learning_rate:12.3e}  │{self._time():>12}  {self.loading_bar(progress)}\",\n",
    "                end=\"\",\n",
    "                flush=True,\n",
    "            )\n",
    "\n",
    "    def _eval_step(self, loss, accuracy) -> None:\n",
    "        self.epoch_state[\"loss\"] += loss.sum().item()\n",
    "        self.epoch_state[\"accuracy\"] += accuracy.sum().item()\n",
    "        self.epoch_state[\"steps\"] += loss.size(0)\n",
    "\n",
    "    def _reset(self, len_dataset: int) -> None:\n",
    "        self.start_time = time.time()\n",
    "        self.step = 0\n",
    "        self.len_dataset = len_dataset\n",
    "        self.epoch_state = {\"loss\": 0.0, \"accuracy\": 0.0, \"steps\": 0}\n",
    "\n",
    "    def _time(self) -> str:\n",
    "        time_seconds = int(time.time() - self.start_time)\n",
    "        return f\"{time_seconds // 60:02d}:{time_seconds % 60:02d} min\"\n",
    "\n",
    "    def _print_header(self) -> None:\n",
    "        print(\n",
    "            f\"┏━━━━━━━━━━━━━━┳━━━━━━━╸T╺╸R╺╸A╺╸I╺╸N╺━━━━━━━┳━━━━━━━╸S╺╸T╺╸A╺╸T╺╸S╺━━━━━━━┳━━━━━━━╸V╺╸A╺╸L╺╸I╺╸D╺━━━━━━━┓\")\n",
    "        print(\n",
    "            f\"┃              ┃              ╷              ┃              ╷              ┃              ╷              ┃\")\n",
    "        print(\n",
    "            f\"┃       epoch  ┃        loss  │    accuracy  ┃        l.r.  │     elapsed  ┃        loss  │    accuracy  ┃\")\n",
    "        print(\n",
    "            f\"┠──────────────╂──────────────┼──────────────╂──────────────┼──────────────╂──────────────┼──────────────┨\")\n",
    "\n",
    "    def _print_footer(self) -> None:\n",
    "        print(\n",
    "            f\"┗━━━━━━━━━━━━━━┻━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┻━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┻━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training loop\n",
    "Use tensor board to record progress and history"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model/dropout': 0.3, 'model/depth': 16, 'model/width_factor': 8, 'SAM/rho': 1, 'SAM/adaptive': True, 'SGD/lr': 0.1, 'SGD/momentum': 0.9, 'SGD/weight_decay': 0.0005, 'SGD/nesterov': True, 'total_epochs': 10, 'loss/label_smoothing': 0.1}\n",
      "┏━━━━━━━━━━━━━━┳━━━━━━━╸T╺╸R╺╸A╺╸I╺╸N╺━━━━━━━┳━━━━━━━╸S╺╸T╺╸A╺╸T╺╸S╺━━━━━━━┳━━━━━━━╸V╺╸A╺╸L╺╸I╺╸D╺━━━━━━━┓\n",
      "┃              ┃              ╷              ┃              ╷              ┃              ╷              ┃\n",
      "┃       epoch  ┃        loss  │    accuracy  ┃        l.r.  │     elapsed  ┃        loss  │    accuracy  ┃\n",
      "┠──────────────╂──────────────┼──────────────╂──────────────┼──────────────╂──────────────┼──────────────┨\n",
      "┃           1  ┃      0.1953  │     91.05 %  ┃   1.000e-01  │   00:03 min  ┃      0.1799  │     91.72 %  ┃\n",
      "┃           2  ┃      0.1932  │     91.14 %  ┃   1.000e-01  │   00:03 min  ┃      0.2795  │     88.80 %  ┃\n",
      "┃           3  ┃      0.1935  │     91.25 %  ┃   1.000e-01  │   00:03 min  ┃      0.1727  │     92.13 %  ┃\n",
      "┃           4  ┃      0.1491  │     93.19 %  ┃   2.000e-02  │   00:03 min  ┃      0.1219  │     94.34 %  ┃\n",
      "┃           5  ┃      0.1379  │     93.70 %  ┃   2.000e-02  │   00:03 min  ┃      0.1225  │     94.36 %  ┃\n",
      "┃           6  ┃      0.1340  │     93.90 %  ┃   2.000e-02  │   00:03 min  ┃      0.1142  │     94.64 %  ┃\n",
      "┃           7  ┃      0.1214  │     94.55 %  ┃   4.000e-03  │   00:03 min  ┃      0.1083  │     95.00 %  ┃\n",
      "┃           8  ┃      0.1188  │     94.62 %  ┃   4.000e-03  │   00:03 min  ┃      0.1073  │     95.01 %  ┃\n",
      "┃           9  ┃      0.1150  │     94.82 %  ┃   8.000e-04  │   00:03 min  ┃      0.1065  │     95.01 %  ┃\n",
      "┃           9  ┃      0.1134  │     94.88 %  ┃   8.000e-04  │   00:03 min  ┃      0.1063  │     95.03 %  ┃\n",
      "┗━━━━━━━━━━━━━━┻━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┻━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┻━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛\n",
      "loss: 0.10632809283733367, accuracy: 0.9503\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "def training(train_dl, test_dl, model, optimizer, scheduler, total_epochs, device, start_epoch=0, writer=None):\n",
    "    with Log(log_each=1, initial_epoch=start_epoch - 1, writer=writer) as log:\n",
    "        for epoch in range(start_epoch, total_epochs):\n",
    "            model.train()\n",
    "            log.train(len_dataset=len(train_dl))\n",
    "\n",
    "            for nb, batch in enumerate(train_dl):\n",
    "                inputs, targets = (b.to(device) for b in batch)\n",
    "\n",
    "                # first forward-backward step\n",
    "                predictions = model(inputs)\n",
    "                loss = smooth_crossentropy(predictions, targets, smoothing=0.1)\n",
    "                loss.mean().backward()\n",
    "                optimizer.first_step(zero_grad=True)\n",
    "\n",
    "                # second forward-backward step\n",
    "                with disable_running_stats(model):\n",
    "                    smooth_crossentropy(model(inputs), targets, smoothing=0.1).mean().backward()\n",
    "                    optimizer.second_step(zero_grad=True)\n",
    "\n",
    "                # gather stats and update learning rate\n",
    "                with torch.no_grad():\n",
    "                    correct = torch.argmax(predictions.data, 1) == targets\n",
    "                    log(model, loss.cpu(), correct.cpu(), scheduler.lr())\n",
    "                    scheduler(epoch)\n",
    "\n",
    "            # update stat on test set\n",
    "            model.eval()\n",
    "            log.eval(len_dataset=len(test_dl))\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for batch in test_dl:\n",
    "                    inputs, targets = (b.to(device) for b in batch)\n",
    "                    predictions = model(inputs)\n",
    "                    loss = smooth_crossentropy(predictions, targets)\n",
    "                    correct = torch.argmax(predictions, 1) == targets\n",
    "                    log(model, loss.cpu(), correct.cpu())\n",
    "        final_loss, final_accuracy = log.loss(), log.accuracy()\n",
    "    return final_loss, final_accuracy\n",
    "\n",
    "\n",
    "with SummaryWriter() as writer:\n",
    "    print(hparams)\n",
    "    # dataset.test.next\n",
    "    loss, accuracy = training(train_dl=dataset.train, test_dl=dataset.test, model=model, optimizer=optimizer,\n",
    "                              scheduler=scheduler,\n",
    "                              total_epochs=hparams[\"total_epochs\"], device=device, writer=writer)\n",
    "    print(F\"loss: {loss}, accuracy: {accuracy}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Applying result to unrelated images and form resulting json"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img1: Bag with 88.45% probability\n",
      "img2: Bag with 88.27% probability\n",
      "img3: Bag with 92.54% probability\n",
      "{'test_acc': 0.9503, 'top_predictions': {'img1': {'Bag': 0.88}, 'img2': {'Bag': 0.88}, 'img3': {'Bag': 0.93}}}\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "result = {\"test_acc\": accuracy, \"top_predictions\": {}}\n",
    "\n",
    "model.eval()\n",
    "for image_fname in ['images/img1.jpg', 'images/img2.jpg', 'images/img3.jpg']:\n",
    "    img = dataset.infer_transform(Image.open(image_fname))[None, :]\n",
    "    with torch.no_grad():\n",
    "        infer = model(img.to(device))\n",
    "    cl = int(infer.argmax(1)[0])\n",
    "    cl_name = dataset.classes[cl]\n",
    "    prob = F.softmax(infer, dim=1).cpu().numpy()[0, cl].astype(float)\n",
    "    short_fname = str(Path(image_fname).stem)\n",
    "    print(f\"{short_fname}: {cl_name} with {100 * prob:.2f}% probability\")\n",
    "    result[\"top_predictions\"][short_fname] = {cl_name : round(prob, 2)}\n",
    "print (result)\n",
    "with open('result.json', 'w') as f:\n",
    "    json.dump(result, f, indent=2)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
